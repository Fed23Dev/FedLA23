# resource config
exp_name: cifar10-vgg16-avg

# checkpoint config
model: vgg16
alg: fedavg
gpu_ids: [0, 1]
# pre_train: True

# dataset config
dataset: cifar10
batch_size: 32

# optimizer config
# optim: sgd
optim: sgd
learning_rate: 0.01

# scheduler config
scheduler: warmup_cos_lr
warm_steps: 80
min_lr: 0.0

# federal config
federal: True
non_iid: shards
workers: 100
active_workers: 2
federal_round: 500
local_epoch: 10

# federal_round: 11
# local_epoch: 1
logits_batch_limit: 50

merge_batch: 0
merge_epoch: 0

KD_BATCH: 10
KD_EPOCH: 128

ALPHA: 1
BETA: 8
